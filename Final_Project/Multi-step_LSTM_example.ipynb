{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "https://blog.csdn.net/weixin_39653948/article/details/105385622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Bidirectional\n",
    "from tensorflow.keras.layers import TimeDistributed, RepeatVector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MultiStepModels:\n",
    "    '''\n",
    "    多時間步 預測 時間序列 LSTM 模型\n",
    "    '''\n",
    "\n",
    "    def __init__(self, train_seq, test_seq, sw_width, pred_length,\n",
    "                 features, epochs_num, verbose_set, flag = 0):\n",
    "        self.train_seq = train_seq\n",
    "        self.test_seq = test_seq\n",
    "        self.sw_width = sw_width\n",
    "        self.pred_length = pred_length\n",
    "\n",
    "        self.features = features\n",
    "        self.epochs_num = epochs_num\n",
    "\n",
    "        # verbose = 0 为不在标准输出流输出日志信息\n",
    "        # verbose = 1 为输出进度条记录\n",
    "        # verbose = 2 为每个epoch输出一行记录\n",
    "        self.verbose_set = verbose_set\n",
    "\n",
    "        self.flag = flag\n",
    "\n",
    "        self.X, self.y = [], []\n",
    "\n",
    "    def split_sequence(self):\n",
    "        '''\n",
    "        該 函數 實現 多輸入序列數據的樣本劃分\n",
    "        '''\n",
    "\n",
    "        for i in range(len(self.train_seq)):\n",
    "            # 找到最後一個元素的索引，因為for循環中i從1開始，切片索引從0開始，切片區間前閉後開，所以不用減去1;\n",
    "            end_index = i + self.sw_width\n",
    "\n",
    "            # 找到須要預測指定時間步長的最後一個元素之索引;\n",
    "            out_end_index = end_index + self.pred_length\n",
    "\n",
    "            # 如果最後一個期望 輸出最後一個元素的索引 大於 序列中最後一元素的索引則丟棄該樣本;\n",
    "            # 這裡len(self.sequence)沒有減去1的原因是：保證最後一個元素的索引剛好等於序列數據索引的時候，能夠擷取到該樣本;\n",
    "            if out_end_index > len(self.train_seq):\n",
    "                break\n",
    "\n",
    "            # 實現以 滑動步伐 為 1，窗口寬度為 self.sw_width 的滑動步伐 取值。\n",
    "            seq_x, seq_y = self.train_seq[i:end_index], self.train_seq[end_index:out_end_index]\n",
    "            self.X.append(seq_x)\n",
    "            self.y.append(seq_y)\n",
    "\n",
    "        self.X, self.y = np.array(self.X), np.array(self.y)\n",
    "        self.X = self.X.reshape((self.X.shape[0], self.X.shape[1], self.features))\n",
    "        self.test_seq = self.test_seq.reshape((1, self.sw_width, self.features))\n",
    "\n",
    "        # 什麼意思？\n",
    "        if self.flag == 1:\n",
    "            self.y = self.y.reshape((self.y.shape[0], self.y.shape[1], self.features))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        for i in range(len(self.X)):\n",
    "            print(self.X[i], self.y[i])\n",
    "\n",
    "\n",
    "        print('X:\\n{} \\n\\ny:\\n{} \\n\\ntest_seq:\\n{} \\n'.format(self.X, self.y, self.test_seq))\n",
    "        print('X.shape:{}, y.shape:{}, test_seq.shape:{}\\n'.format(self.X.shape, self.y.shape, self.test_seq.shape))\n",
    "\n",
    "        return self.X, self.y, self.test_seq\n",
    "\n",
    "    def stacked_lstm(self):\n",
    "        print(f'X.shpae: {self.X.shape}')\n",
    "        print(f'y.shape: {self.y.shape}')\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(100, activation='relu', return_sequences=True,\n",
    "                       input_shape = (self.sw_width, self.features)))\n",
    "        model.add(LSTM(100, activation='relu'))\n",
    "        model.add(Dense(units=self.pred_length))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "\n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']),\n",
    "              '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('y^hat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "\n",
    "    def encoder_decoder_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(100, activation='relu',\n",
    "                       input_shape = (self.sw_width, self.features)))\n",
    "        model.add(RepeatVector(self.pred_length))\n",
    "        model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "\n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']),\n",
    "              '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('y^hat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "#\n",
    "# dataframe = pd.read_csv('data_processed/Ba_Leng/2019_Ba_Leng_Rainfall.csv')\n",
    "# dataframe['Time'] = pd.to_datetime(dataframe['Time'])\n",
    "# dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# filter = (dataframe[\"Month\"] == 8)\n",
    "# by_month = dataframe[filter]\n",
    "# by_month"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# start, end = 170, 210\n",
    "# x_axis_data = by_month[[\"Time\"]][start:end]\n",
    "#\n",
    "# y_axis_data = by_month[[\"Rainfall\"]][start:end]\n",
    "#\n",
    "# plt.plot(x_axis_data, y_axis_data)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# train_seq = np.array(y_axis_data[0:28])\n",
    "# test_seq = np.array(y_axis_data[21:28])\n",
    "# train_seq = np.squeeze(train_seq)\n",
    "# test_seq = np.squeeze(test_seq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------以下為【向量輸出 LSTM 模型 】相關訊息-------\n",
      "[[10]\n",
      " [20]\n",
      " [30]] [40 50]\n",
      "[[20]\n",
      " [30]\n",
      " [40]] [50 60]\n",
      "[[30]\n",
      " [40]\n",
      " [50]] [60 70]\n",
      "[[40]\n",
      " [50]\n",
      " [60]] [70 80]\n",
      "[[50]\n",
      " [60]\n",
      " [70]] [80 90]\n",
      "X:\n",
      "[[[10]\n",
      "  [20]\n",
      "  [30]]\n",
      "\n",
      " [[20]\n",
      "  [30]\n",
      "  [40]]\n",
      "\n",
      " [[30]\n",
      "  [40]\n",
      "  [50]]\n",
      "\n",
      " [[40]\n",
      "  [50]\n",
      "  [60]]\n",
      "\n",
      " [[50]\n",
      "  [60]\n",
      "  [70]]] \n",
      "\n",
      "y:\n",
      "[[40 50]\n",
      " [50 60]\n",
      " [60 70]\n",
      " [70 80]\n",
      " [80 90]] \n",
      "\n",
      "test_seq:\n",
      "[[[70]\n",
      "  [80]\n",
      "  [90]]] \n",
      "\n",
      "X.shape:(5, 3, 1), y.shape:(5, 2), test_seq.shape:(1, 3, 1)\n",
      "\n",
      "X.shpae: (5, 3, 1)\n",
      "y.shape: (5, 2)\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 3, 100)            40800     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,402\n",
      "Trainable params: 121,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "train_acc:0.9822000001817942 \n",
      "train_loss:67.02011449423043\n",
      "y^hat:[[102.98762 114.86429]] \n",
      "-----------------------------\n",
      "-------以下為【編碼器-解碼器 LSTM 模型 】相關訊息-------\n",
      "[[10]\n",
      " [20]\n",
      " [30]] [[40]\n",
      " [50]]\n",
      "[[20]\n",
      " [30]\n",
      " [40]] [[50]\n",
      " [60]]\n",
      "[[30]\n",
      " [40]\n",
      " [50]] [[60]\n",
      " [70]]\n",
      "[[40]\n",
      " [50]\n",
      " [60]] [[70]\n",
      " [80]]\n",
      "[[50]\n",
      " [60]\n",
      " [70]] [[80]\n",
      " [90]]\n",
      "X:\n",
      "[[[10]\n",
      "  [20]\n",
      "  [30]]\n",
      "\n",
      " [[20]\n",
      "  [30]\n",
      "  [40]]\n",
      "\n",
      " [[30]\n",
      "  [40]\n",
      "  [50]]\n",
      "\n",
      " [[40]\n",
      "  [50]\n",
      "  [60]]\n",
      "\n",
      " [[50]\n",
      "  [60]\n",
      "  [70]]] \n",
      "\n",
      "y:\n",
      "[[[40]\n",
      "  [50]]\n",
      "\n",
      " [[50]\n",
      "  [60]]\n",
      "\n",
      " [[60]\n",
      "  [70]]\n",
      "\n",
      " [[70]\n",
      "  [80]]\n",
      "\n",
      " [[80]\n",
      "  [90]]] \n",
      "\n",
      "test_seq:\n",
      "[[[70]\n",
      "  [80]\n",
      "  [90]]] \n",
      "\n",
      "X.shape:(5, 3, 1), y.shape:(5, 2, 1), test_seq.shape:(1, 3, 1)\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 2, 100)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 2, 100)            80400     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 2, 1)             101       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    train_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    test_seq = np.array([70, 80, 90])\n",
    "\n",
    "    sliding_window_width = 3\n",
    "    predict_length = 2\n",
    "    n_features = 1\n",
    "\n",
    "    epoch_num = 1000\n",
    "    verbose_set = 0\n",
    "\n",
    "    print('-------以下為【向量輸出 LSTM 模型 】相關訊息-------')\n",
    "    MultiStepLSTM = MultiStepModels(train_seq, test_seq, sliding_window_width, predict_length,\n",
    "                                    n_features, epoch_num, verbose_set)\n",
    "    MultiStepLSTM.split_sequence()\n",
    "    MultiStepLSTM.stacked_lstm()\n",
    "\n",
    "    print('-------以下為【編碼器-解碼器 LSTM 模型 】相關訊息-------')\n",
    "    MultiStepLSTM = MultiStepModels(train_seq, test_seq, sliding_window_width, predict_length,\n",
    "                                    n_features, epoch_num, verbose_set, flag=1)\n",
    "    MultiStepLSTM.split_sequence()\n",
    "    MultiStepLSTM.encoder_decoder_lstm()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}